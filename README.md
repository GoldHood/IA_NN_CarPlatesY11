# üöó Deteci√≥n de Placas PER√ö üì∑üî¢

![status-beta](https://img.shields.io/badge/status-beta-yellow) ![python-3.8+](https://img.shields.io/badge/python-3.8%2B-blue) ![PyTorch](https://img.shields.io/badge/framework-PyTorch-red) ![Colab-Ready](https://img.shields.io/badge/Colab-‚úÖ-orange) ![version-1.2.0](https://img.shields.io/badge/version-1.2.0-orange)

**Autor principal**: Ing. Mg. Martin Verastegui Ponce ‚Äì Mag√≠ster en Inteligencia Artificial  
**Correo**: martin.verastegui@gmail.com  
**√öltima actualizaci√≥n**: 22-may-2025

---

## üåü Resumen Ejecutivo
**IA_NN_CarPlatesY11** es un prototipo integral de *Computer Vision* y *Deep Learning* para **detectar** y **leer** matr√≠culas vehiculares peruanas üáµüá™ (extensible a LATAM üåé) usando **PyTorch**. El flujo completo ‚Äìdesde la preparaci√≥n del dataset hasta el despliegue en Docker y Google Colab‚Äì est√° documentado en el notebook `MVP_Placas_peru_Y11_10epoch_V3.ipynb` (10 √©pocas). Este README reescribe y ampl√≠a **cada celda de notas** del notebook, proporcionando un manual exhaustivo y auto contenible.

---

## üó∫Ô∏è Mapa R√°pido del Proyecto
| Secci√≥n | ¬øQu√© encontrar√°s? | 
|---|---|
| [Caracter√≠sticas](#caracter√≠sticas) | Lista resumida de ‚Äúsuper-poderes‚Äù del sistema |
| [Tecnolog√≠as](#tecnolog√≠as) | Stack de software 100 % PyTorch |
| [Arquitectura](#arquitectura-de-la-red) | Diagrama textual del pipeline CNN + YOLO + OCR |
| [Estructura de Archivos](#estructura-de-archivos) | √Årbol de carpetas comentado |
| [Instalaci√≥n & Colab](#instalaci√≥n--demo-colab) | Setup local üñ•Ô∏è y en la nube ‚òÅÔ∏è |
| [Uso](#instrucciones-de-uso) | Comandos de inferencia con tips de confianza |
| [Entrenamiento](#entrenamiento-10-√©pocas) | Par√°metros por defecto y c√≥mo cambiarlos |
| [Detalles del Notebook](#pipeline-detallado-del-notebook) | Explicaci√≥n celda-por-celda |
| [Resultados](#evaluaci√≥n--resultados) | M√©tricas + an√°lisis de errores |
| [Despliegue](#despliegue-api-y-docker) | Exportar ONNX, servir con FastAPI, empaquetar Docker |
| [Preguntas Frecuentes](#faq) | Problemas comunes y soluciones |
| [Glosario](#glosario) | T√©rminos t√©cnicos clave |
| [Roadmap](#roadmap) | Pr√≥ximas mejoras |

---

## ‚≠ê Caracter√≠sticas
- **Detecci√≥n en tiempo real** (‚âà 40 FPS en GPU Tesla T4)  
- **OCR end-to-end** con LSTM + CTC para texto ‚ÄúABC-123‚Äù  
- **Entrenamiento r√°pido**: 10 √©pocas ‚âà 12 min en Colab  
- **Data Augmentation** configurable (Albumentations)  
- **Abstracci√≥n de hiperpar√°metros** v√≠a YAML  
- **Visualizaci√≥n autom√°tica** de bounding boxes y texto reconocido  
- **Exportaci√≥n ONNX** y **servicio REST** listo para producci√≥n  

---

## üîß Tecnolog√≠as
| Categor√≠a | Versiones |
|---|---|
| Lenguaje | Python 3.8 ‚Äì 3.11 |
| DL Framework | PyTorch 2.x + torchvision |
| Visi√≥n | OpenCV ‚â• 4.8, Albumentations ‚â• 1.4 |
| Cuestionario | CUDA 11/12 (opcional) |
| Plotting | Matplotlib, Seaborn (solo gr√°ficos) |
| MLOps | Google Colab, Docker 24, FastAPI 0.110 |

---

## üß† Arquitectura de la Red
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Imagen 512¬≤   ‚îÇ ‚Üí ‚îÇ ResNet34 Backbone ‚îÇ ‚Üí ‚îÇ YOLO Head (BBox) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     features             ‚îÇ
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îÇ
                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                           ‚îÇ OCR Branch LSTM-CTC   ‚îÇ
                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îÇ texto
```
- **Backbone**: ResNet34 con capas congeladas primeras 3 √©pocas para *transfer learning*.  
- **Head de detecci√≥n**: 3 escalas de salida (13√ó13, 26√ó26, 52√ó52) y anclas espec√≠ficas para matr√≠culas horizontales.  
- **OCR**: recorta la ROI detectada, la normaliza a (128√ó32) y la pasa por 2x Conv + 2x Bi-LSTM + CTC.

### P√©rdida total
`Loss = Œª1 * YOLO_Loss + Œª2 * CTC_Loss`  
Con Œª1 = 1.0 y Œª2 = 0.8 tras *grid search*.

---

## üìÇ Estructura de Archivos
```text
IA_NN_CarPlatesY11/
‚îú‚îÄ‚îÄ data/                  # Dataset original + splits
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ labels/
‚îÇ   ‚îî‚îÄ‚îÄ splits/{train,val,test}.txt
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ MVP_Placas_peru_Y11_10epoch_V3.ipynb  # Demo Colab paso a paso
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ train.py           # Loop de entrenamiento comentado
‚îÇ   ‚îú‚îÄ‚îÄ detect.py          # Inferencia CLI / v√≠deo
‚îÇ   ‚îú‚îÄ‚îÄ ocr.py             # OCR stand-alone
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py     # Dataset + augmentations
‚îÇ   ‚îú‚îÄ‚îÄ utils.py           # IoU, NMS, m√©tricas, dibujo
‚îÇ   ‚îî‚îÄ‚îÄ export_onnx.py     # Conversi√≥n a ONNX  opset 17
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îî‚îÄ‚îÄ train.yaml         # Hiperpar√°metros por defecto
‚îú‚îÄ‚îÄ models/                # Checkpoints .pt
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ curves.png         # Loss & metrics history
‚îÇ   ‚îî‚îÄ‚îÄ vis/               # Ejemplos de detecci√≥n
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile         # Imagen GPU
‚îÇ   ‚îî‚îÄ‚îÄ start.sh           # Script de arranque FastAPI
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## ‚öôÔ∏è Instalaci√≥n &amp; Demo Colab
### Ejecuci√≥n Local
1. Clonar repositorio:  
   `git clone https://github.com/GoldHood/IA_NN_CarPlatesY11.git`  
   `cd IA_NN_CarPlatesY11`
2. Crear entorno:  
   `python -m venv venv && source venv/bin/activate`  
3. Instalar:  
   `pip install -r requirements.txt`
4. Descargar dataset (link en `data/README_dataset.md`).

### Google Colab *One-Click*
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GoldHood/IA_NN_CarPlatesY11/blob/main/notebooks/MVP_Placas_peru_Y11_10epoch_V3.ipynb)

---

## üöÄ Instrucciones de Uso
#### Detecci√≥n single-image
```
python src/detect.py \
  --weights models/best.pt \
  --source data/images/ejemplo.jpg \
  --conf-thres 0.25 \
  --iou-thres 0.5 \
  --output results/
```
#### Detecci√≥n en tiempo real (webcam)
```
python src/detect.py --weights models/best.pt --source 0 --view-img
```

---

## üèãÔ∏è Entrenamiento (10 √©pocas)
```
python src/train.py \
  --config configs/train.yaml \
  --epochs 10 \
  --batch-size 16 \
  --img-size 512 \
  --workers 4
```
- **Optimizaci√≥n**: AdamW (lr = 1e-4), scheduler CosineAnnealing.  
- **Early Stopping**: se detiene si el F1-score no mejora en 3 √©pocas.

---

## üìä Evaluaci√≥n & Resultados

## üìã Evaluaci√≥n Final del Modelo YOLOv11 sobre Validaci√≥n en 100 √âpocas üß™

El modelo ha sido evaluado usando el conjunto de validaci√≥n especificado en `data.yaml`. A continuaci√≥n se presentan y explican los resultados clave obtenidos tras 100 √©pocas de entrenamiento:

---

### üß† M√©tricas Generales:

| M√©trica                        | Valor   | Interpretaci√≥n                                                                 |
|-------------------------------|---------|-------------------------------------------------------------------------------|
| `Precision`                   | **0.921** | De todas las placas que el modelo predijo, el **92.1%** fueron correctas.     |
| `Recall`                      | **0.934** | El modelo detect√≥ el **93.4%** de las placas reales en las im√°genes.          |
| `mAP@0.5`                     | **0.949** | Precisi√≥n promedio cuando el IoU ‚â• 0.5. Muy alto ‚Üí detecciones precisas.      |
| `mAP@0.5:0.95`                | **0.692** | Promedio de mAP en 10 umbrales (de 0.5 a 0.95). Buen resultado, m√°s exigente. |
| `Fitness`                     | **0.718** | Valor global de ajuste del modelo (ponderaci√≥n de todas las m√©tricas).        |

---

### üìå Clases Detectadas:

| Clase   | Im√°genes | Instancias | Precision | Recall | mAP@0.5 | mAP@0.5:0.95 |
|---------|----------|------------|-----------|--------|---------|--------------|
| `Placa` | 106      | 203        | 0.930     | 0.887  | 0.919   | 0.612        |
| `placa` | 32       | 54         | 0.912     | 0.981  | 0.979   | 0.772        |

> ‚ö†Ô∏è *Nota:* Se siguen identificando dos clases similares (`Placa` y `placa`). Se recomienda unificar estas etiquetas en el dataset para evitar confusiones y mejorar la coherencia de la evaluaci√≥n.

---

## üìã Evaluaci√≥n del Modelo YOLOv11 ‚Äî 22 √âpocas üß™

Este modelo fue entrenado para la detecci√≥n de placas peruanas. A continuaci√≥n se presentan sus m√©tricas clave evaluadas en el conjunto de validaci√≥n:

### üß† M√©tricas Generales:

| M√©trica        | Valor   | Significado |
|----------------|---------|-------------|
| `Precision`    | **0.888** | De todas las predicciones positivas, el 88.8% fueron verdaderas. |
| `Recall`       | **0.907** | Detect√≥ el 90.7% de las placas reales en las im√°genes. |
| `mAP@0.5`      | **0.927** | Alta precisi√≥n media cuando el IoU ‚â• 0.5. |
| `mAP@0.5:0.95` | **0.714** | Media de precisi√≥n bajo umbrales m√°s estrictos (IoU de 0.5 a 0.95). |
| `Fitness`      | **0.709** | Valor compuesto de rendimiento (considera todas las m√©tricas anteriores). |

---

### üìå Clases Detectadas:

| Clase   | Im√°genes | Instancias | Precision | Recall | mAP@0.5 | mAP@0.5:0.95 |
|---------|----------|------------|-----------|--------|---------|--------------|
| `placa` | 121      | 228        | 0.888     | 0.907  | 0.927   | 0.714        |

> ‚úÖ El modelo ya no tiene clases duplicadas como `Placa` y `placa`. Se logr√≥ una **unificaci√≥n de clase**.

---

### ‚ö° Velocidad de procesamiento:

- **Preprocesamiento:** 2.5 ms / imagen
- **Inferencia:** 4.2 ms / imagen
- **Postproceso:** 3.0 ms / imagen

---

### ‚úÖ Conclusiones

- üü¢ El modelo muestra un **rendimiento s√≥lido** tras solo 22 √©pocas de entrenamiento.
- üß™ Apto para **entornos en tiempo real** gracias a su baja latencia.
- üìà Se puede seguir mejorando con m√°s ejemplos extremos o entrenamiento extendido.
- üîÑ Ya se solucion√≥ la duplicaci√≥n de etiquetas (`Placa` vs `placa`).



### ‚ö° Velocidad de procesamiento:

- **Preprocesamiento:** 2.4 ms / imagen
- **Inferencia:** 4.2 ms / imagen
- **Postproceso:** 3.0 ms / imagen

‚úÖ Ideal para **aplicaciones en tiempo real** sobre GPUs como Tesla T4.


Las curvas de entrenamiento se generan autom√°ticamente en `results/curves.png`.

---

## üìò Pipeline detallado del Notebook
1. **Setup Colab**: instala dependencias y configura GPU (12 GB).  
2. **Exploraci√≥n del dataset**: muestra histograma de longitudes de texto y ejemplos balanceados.  
3. **DataLoader**: `Albumentations` con `Compose([RandomBrightnessContrast, MotionBlur, ‚Ä¶])`.  
4. **Definici√≥n del modelo**: subclase `torch.nn.Module`, imprime `summary()` con 9,2 M par√°metros.  
5. **Funci√≥n de p√©rdida**: combina `bbox_loss` + `objectness_loss` + `ctc_loss`.  
6. **Loop de entrenamiento**: tqdm por batch, calcula m√©tricas cada √©poca y guarda `best.pt`.  
7. **Validaci√≥n**: confusion matrix + logging a TensorBoard.  
8. **Demo v√≠deo**: procesa `data/videos/highway.mp4`, calcula FPS, escribe `results/demo_highway.mp4`.  
9. **Export ONNX**: script `export_onnx.py`, verificado con `onnxruntime`.  

Cada celda contiene comentarios que explican *por qu√©* y *c√≥mo* se hace cada paso.

---

## üõ∞Ô∏è Despliegue API y Docker
1. Construir imagen:  
   `docker build -t carplates-api -f docker/Dockerfile .`
2. Ejecutar:  
   `docker run --gpus all -p 8000:8000 carplates-api`
3. Consumir:  
   `curl -F "image=@car.jpg" http://localhost:8000/predict`

La API devuelve JSON con bounding box y texto: `{"plate":"ABC-123","conf":0.94}`.

---

## üõ†Ô∏è Troubleshooting
- **CUDA OOM**: reduce `--batch-size` o usa `--img-size 416`.  
- **Results vac√≠os**: verifica `--conf-thres`; baja a 0.1 para depurar.  
- **OCR confuso**: aseg√∫rate de que `tesseract` no est√© en PATH; la red ya contiene OCR.

---

## ‚ùì FAQ
> **¬øPuedo entrenar con menos de 500 im√°genes?**  
> S√≠, pero recomendamos *transfer learning* y congelar m√°s capas.

> **¬øFunciona con motos o camiones?**  
> S√≠, siempre que la matr√≠cula siga el patr√≥n alfanum√©rico entrenado.

---

## üìö Glosario
- **BBox**: *Bounding Box* ‚Äì caja delimitadora.  
- **CTC**: *Connectionist Temporal Classification* loss para secuencias.  
- **mAP@0.5**: media de AP con IoU m√≠nimo 0.5.  
- **IoU**: *Intersection over Union* m√©trica de solapamiento.  
- **NMS**: *Non-Max Suppression* para descartar cajas redundantes.

---

## üöß Roadmap
- [x] Exportaci√≥n ONNX + demo Colab  
- [ ] Integraci√≥n CI/CD (GitHub Actions + pytest)  
- [ ] Soporte placas de üá®üá± Chile y üá≤üáΩ M√©xico  
- [ ] Panel de monitoreo con Grafana + Prometheus  
- [ ] Auto-labeling semi supervisado con CLIP + SAM

---

## ü§ù Contribuir
1. **Fork** üç¥ y crea rama: `git checkout -b feature/nueva-funcion`  
2. Ejecuta `pre-commit install` para formateo autom√°tico  
3. A√±ade tests en `tests/` y notebook de ejemplo  
4. Abre Pull Request con descripci√≥n clara

---

## üìÑ Licencia
MIT ¬© 2025 Ing. Mg. Martin Verastegui Ponce ‚Äì Todos los derechos preservados.

---

## üôè Agradecimientos
- Comunidad **PyTorch** y **OpenCV** por herramientas open-source  
- Equipo **Punto Verde** por el dataset inicial  
- **Google Colab** por GPU gratuita para demos  

**¬°Gracias por leer!** Si este proyecto te ayud√≥, deja una ‚≠ê y comparte tu feedback üöÄ

